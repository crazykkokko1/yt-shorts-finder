import streamlit as st
import requests
import datetime
import isodate
import re

API_KEY = "AIzaSyBOOMku1-aa28MuQsJpOpxh0hrwvyvpHKo"  # ì—¬ê¸°ì— ë³¸ì¸ì˜ YouTube Data API í‚¤ ì…ë ¥

# Streamlit ì„¤ì •
st.set_page_config(page_title="ğŸ”¥ ì§€ê¸ˆ ëœ¨ëŠ” ìœ íŠœë¸Œ Shorts", layout="wide")
st.title(":fire: ì§€ê¸ˆ ëœ¨ëŠ” ìœ íŠœë¸Œ Shorts")

# ë‚ ì§œ ì¡°ê±´
date_option = st.radio("ì¡°íšŒ ê¸°ê°„ ì„ íƒ", ["ìµœê·¼ 3ì¼", "ìµœê·¼ 7ì¼", "í‹€ì • ë‚ ì§œ"])
if date_option == "í‹€ì • ë‚ ì§œ":
    selected_date = st.date_input("ê¸°ì¤€ ë‚ ì§œ", datetime.date.today())
    published_after = datetime.datetime.combine(selected_date, datetime.datetime.min.time()).isoformat("T") + "Z"
else:
    days = 3 if date_option == "ìµœê·¼ 3ì¼" else 7
    published_after = (datetime.datetime.utcnow() - datetime.timedelta(days=days)).isoformat("T") + "Z"

# ì–¸ì–´ í•„í„°
exclude_korean = st.checkbox("í•œêµ­ì–´ í¬í•¨ ì˜ìƒ ì œì™¸")

# ì°¨ë‹¨ ì±„ë„
blocked_ids_raw = st.text_input("ì°¨ë‹¨í•  ì±„ë„ ID (ì‰¼í¬ë¡œ êµ¬ë¶„)", "")
blocked_ids = [cid.strip() for cid in blocked_ids_raw.split(",") if cid.strip()]

# ìµœëŒ€ ê°œìˆ˜
max_results = st.slider("ìµœëŒ€ ê²°ê³¼ ê°œìˆ˜", 10, 100, 50, step=10)

# ì¢‹ì•„ìš”ìœ¨ ë†’ì€ ì˜ìƒ, ì¡°íšŒìˆ˜ ì¦ê°€ ì†ë„ ë¹ ë¥¸ ì˜ìƒ í•„í„°
filter_likes = st.checkbox(":thumbsup: ì¢‹ì•„ìš”ìœ¨ ë†’ì€ ì˜ìƒë§Œ ë³´ê¸°")
filter_velocity = st.checkbox(":rocket: ì¡°íšŒìˆ˜ ì¦ê°€ ì†ë„ ë†’ì€ ì˜ìƒë§Œ ë³´ê¸°")

# ì •ë ¬ ê¸°ì¤€
sort_by = st.selectbox("ì •ë ¬ ê¸°ì¤€", ["ì¡°íšŒìˆ˜", "ì¢‹ì•„ìš”ìˆ˜", "ì—…ë¡œë“œì¼"])
order_map = {
    "ì¡°íšŒìˆ˜": "viewCount",
    "ì¢‹ì•„ìš”ìˆ˜": "rating",
    "ì—…ë¡œë“œì¼": "date"
}

# ì‹¤í–‰ ë²„íŠ¼
if st.button(":fire: ì§€ê¸ˆ ë›°ëŠ” ì‡¼ì¸ "):
    st.info("YouTube Shorts ì˜ìƒì„ ìˆ˜ì§‘ ì¤‘...")

    # 1ë‹¨ê³„: ê²€ìƒ‰í•´ì„œ ì˜ìƒ ID ìˆ˜ì§‘
    search_url = "https://www.googleapis.com/youtube/v3/search"
    video_ids = []
    page_token = None

    while len(video_ids) < max_results:
        params = {
            "part": "snippet",
            "maxResults": min(50, max_results - len(video_ids)),
            "order": order_map.get(sort_by, "viewCount"),
            "publishedAfter": published_after,
            "type": "video",
            "videoDuration": "short",
            "key": API_KEY
        }
        if page_token:
            params["pageToken"] = page_token

        res = requests.get(search_url, params=params).json()
        items = res.get("items", [])
        for item in items:
            video_ids.append(item["id"]["videoId"])
        page_token = res.get("nextPageToken")
        if not page_token:
            break

    st.success(f"\ud558\ub098\ub3c4 \uac80\uc0c9\ub418\ub294 ID: {len(video_ids)}")
    if not video_ids:
        st.error("YouTube API\uc5d0\uc11c \uc601\uc0c1 ID\ub97c \ucc3e\uc9c0 \ubabb\ud588\uc2b5\ub2c8\ub2e4. \ub0a0\uc9dc \ubc94\uc704 \ub610\ub294 API \ud0a4\ub97c \ud655\uc778\ud574\uc8fc\uc138\uc694.")
        st.stop()

    # 2ë‹¨ê³„: ì˜ìƒ ìƒì„¸ ì •ë³´
    video_details = []
    detail_url = "https://www.googleapis.com/youtube/v3/videos"

    for i in range(0, len(video_ids), 50):
        ids = video_ids[i:i+50]
        params = {
            "part": "snippet,statistics,contentDetails",
            "id": ",".join(ids),
            "key": API_KEY
        }
        res = requests.get(detail_url, params=params).json()
        for video in res.get("items", []):
            try:
                snippet = video["snippet"]
                stats = video["statistics"]
                details = video["contentDetails"]
                
                title = snippet["title"]
                desc = snippet.get("description", "")
                channel = snippet["channelTitle"]
                channel_id = snippet["channelId"]
                view_count = int(stats.get("viewCount", 0))
                like_count = int(stats.get("likeCount", 0)) if "likeCount" in stats else 0
                duration = isodate.parse_duration(details["duration"]).total_seconds()

                if duration > 60:
                    continue
                if exclude_korean and re.search(r"[\uac00-\ud7af]", title + desc):
                    continue
                if channel_id in blocked_ids:
                    continue
                if filter_likes and (like_count / view_count if view_count > 0 else 0) < 0.05:
                    continue
                if filter_velocity and view_count < 1000:
                    continue

                video_details.append({
                    "title": title,
                    "url": f"https://www.youtube.com/watch?v={video['id']}",
                    "views": view_count,
                    "likes": like_count,
                    "duration": int(duration),
                    "channel": channel,
                    "thumbnail": snippet["thumbnails"]["high"]["url"]
                })
            except:
                continue

    if not video_details:
        st.warning("ì¡°ê±´ì— ë§ëŠ” ì˜ìƒì´ ì—†ìŠµë‹ˆë‹¤.")
        st.stop()

    # ì •ë ¬
    if sort_by == "ì¡°íšŒìˆ˜":
        video_details.sort(key=lambda x: x["views"], reverse=True)
    elif sort_by == "ì¢‹ì•„ìš”ìˆ˜":
        video_details.sort(key=lambda x: x["likes"], reverse=True)

    # ì¶œë ¥
    for item in video_details:
        col1, col2 = st.columns([1, 4])
        with col1:
            st.image(item["thumbnail"], width=160)
        with col2:
            st.markdown(f"**{item['title']}**")
            st.markdown(f"ì¡°íšŒìˆ˜: {item['views']:,} / ì¢‹ì•„ìš”: {item['likes']:,} / ê¸¸ì´: {item['duration']}ì´ˆ")
            st.markdown(f"ì±„ë„: {item['channel']}")
            st.markdown(f"[ì˜ìƒ ë³´ê¸°]({item['url']})")
        st.markdown("---")
